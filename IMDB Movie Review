import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer
##labelencoder- connvert categorical sentiments into 0 an 1
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import roc_auc_score, roc_curve

# Load the Excel file
file_path = "C:\\Users\\91931\\OneDrive\\Desktop\\BIA PROJECT\\IMDB Dataset.xlsx"  # Replace with your file path
data = pd.read_excel(file_path)
print(data.head())
def clean_text(text):  
    text = re.sub('<.*?>', '', text) ## re.sub is use to replace with space 
    text = text.lower()
    text = re.sub('[^\w\s]', '', text)
    return text
data['cleaned_review'] = data['review'].apply(clean_text) 
data[['review', 'cleaned_review']].head()
##now Train data set
label_encoder = LabelEncoder()
## created new column sentiment_encoded to transform data into categorical using .fit_transform
data['sentiment_encoded'] = label_encoder.fit_transform(data['sentiment']) 
X = data['cleaned_review']  # (cleaned reviews)
y = data['sentiment_encoded']  # (encoded sentiment)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
len(X_train), len(X_test), len(y_train), len(y_test)
data.head()
# stop words means ('the and') ko hatana and max features for vocalbury size  most frequent words
vectorizer = CountVectorizer(stop_words="english", max_features=5000)
# Fit and transform the text data into catogorical
X_train_bow = vectorizer.fit_transform(X_train)
X_test_bow = vectorizer.transform(X_test)
log_reg = LogisticRegression(C=.00042)
log_reg.fit(X_train_bow, y_train)
y_test_pred = log_reg.predict(X_test_bow)
y_train_pred = log_reg.predict(X_train_bow)
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f"Training Accuracy: {train_accuracy:.4f}")
print("Testing Accuracy", test_accuracy)
print("Classification Report:\n", classification_report(y_test, y_test_pred))
y_probs = log_reg.predict_proba(X_test_bow)[:, 1]
y_pro_bs = log_reg.predict_proba(X_test_bow)[:, 0]
auc_score = roc_auc_score(y_test, y_probs)

print(f"AUC Score: {auc_score:4f}")

fpr, tpr, _ = roc_curve(y_test, y_probs)  # Compute FPR & TPR

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f"AUC = {auc_score:.4f}")  # Plot ROC curve
plt.plot([0, 1], [0, 1], color='red', linestyle='--')  # Diagonal line (random model)
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("ROC Curve")
plt.legend()
plt.show()
